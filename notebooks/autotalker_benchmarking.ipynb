{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b1daabf-c8e3-43d4-aa32-9789abcc8619",
   "metadata": {},
   "source": [
    "# Autotalker Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c325d921-2077-42b3-90a8-6f6c7dd928c5",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-LÃ³pez Lab\n",
    "- **Date of Creation:** 07.12.2022\n",
    "- **Date of Last Modification:** 13.12.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d464ebf-354f-4f61-8040-c3dcbcc893b9",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5631277-d8d2-4194-a376-280f4f149b7d",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e5d3297-0290-47c0-846f-705e74cdb3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dbd4925-7505-4d01-bf91-95b54bb8b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4aa3c6a-5a44-4cf1-84a3-5e514457cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "import squidpy as sq\n",
    "\n",
    "from autotalker.models import Autotalker\n",
    "from autotalker.utils import (add_gps_from_gp_dict_to_adata,\n",
    "                              extract_gp_dict_from_mebocost_es_interactions,\n",
    "                              extract_gp_dict_from_nichenet_ligand_target_mx,\n",
    "                              extract_gp_dict_from_omnipath_lr_interactions,\n",
    "                              filter_and_combine_gp_dict_gps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b886225-6b6d-433c-b117-47b9a8f8091f",
   "metadata": {},
   "source": [
    "### 1.2 Configure Paths and Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36675337-808d-40a9-93fc-d6cfa9473f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "figure_path = \"../figures\"\n",
    "model_artefacts_path = \"../model_artefacts\"\n",
    "gp_data_folder_path = \"../datasets/gp_data/\" # gene program data\n",
    "srt_data_folder_path = \"../datasets/srt_data/\" # spatially resolved transcriptomics data\n",
    "srt_data_gold_folder_path = f\"{srt_data_folder_path}/gold\"\n",
    "nichenet_ligand_target_mx_file_path = gp_data_folder_path + \"nichenet_ligand_target_matrix.csv\"\n",
    "omnipath_lr_interactions_file_path = gp_data_folder_path + \"omnipath_lr_interactions.csv\"\n",
    "\n",
    "# Create required directories\n",
    "os.makedirs(figure_path, exist_ok=True)\n",
    "os.makedirs(model_artefacts_path, exist_ok=True)\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "os.makedirs(gp_data_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6cf198-5909-4c1e-9805-5e494a63412d",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3556ca35-3edf-4c42-84b3-2fe58d5fb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore future warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f91f345-c297-47cb-8650-c6d9c60a8b7e",
   "metadata": {},
   "source": [
    "### 1.4 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4d4e6d9-239f-47c5-a30b-579b16d4c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnnData object\n",
    "dataset = \"squidpy_seqfish_mouse_organogenesis\"\n",
    "counts_key = \"counts\"\n",
    "cell_type_key = \"celltype_mapped_refined\"\n",
    "adj_key = \"spatial_connectivities\"\n",
    "spatial_key = \"spatial\"\n",
    "gp_names_key = \"autotalker_gp_names\"\n",
    "active_gp_names_key = \"autotalker_active_gp_names\"\n",
    "gp_targets_mask_key = \"autotalker_gp_targets\"\n",
    "gp_sources_mask_key = \"autotalker_gp_sources\"\n",
    "latent_key = \"autotalker_latent\"\n",
    "\n",
    "# Others\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc61ed2d-6ed4-45fa-8e74-b919d74000b5",
   "metadata": {},
   "source": [
    "### 1.5 Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfa64ac5-8032-4aea-b36d-4379ffd38e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hyperparam_benchmarking(dataset,\n",
    "                                hyperparam_option_dict,\n",
    "                                n_iters,\n",
    "                                experiment_name,\n",
    "                                gp_mask=\"combined_priors\",\n",
    "                                save_model=False):\n",
    "    # Retrieve gene program mask\n",
    "    print(\"--- GP MASK ---\")\n",
    "    print(f\"Using '{gp_mask}' GP mask.\")\n",
    "    mlflow.log_param(\"gp_mask\", gp_mask)\n",
    "    if gp_mask == \"combined_priors\":\n",
    "        nichenet_keep_target_ratio = 0.01\n",
    "        omnipath_min_curation_effort = 0\n",
    "        gp_filter_mode = \"subset\"\n",
    "        combine_overlap_gps = True\n",
    "        overlap_thresh_source_genes=0.9\n",
    "        overlap_thresh_target_genes=0.9\n",
    "        overlap_thresh_genes=0.9\n",
    "        \n",
    "        nichenet_gp_dict = extract_gp_dict_from_nichenet_ligand_target_mx(\n",
    "            keep_target_ratio=nichenet_keep_target_ratio,\n",
    "            load_from_disk=False,\n",
    "            save_to_disk=True,\n",
    "            file_path=nichenet_ligand_target_mx_file_path)\n",
    "        omnipath_gp_dict = extract_gp_dict_from_omnipath_lr_interactions(\n",
    "            min_curation_effort=omnipath_min_curation_effort,\n",
    "            load_from_disk=False,\n",
    "            save_to_disk=True,\n",
    "            file_path=omnipath_lr_interactions_file_path)\n",
    "        mebocost_gp_dict = extract_gp_dict_from_mebocost_es_interactions(\n",
    "            dir_path = \"../datasets/gp_data/metabolite_enzyme_sensor_gps/\",\n",
    "            species=\"mouse\",\n",
    "            genes_uppercase=True)\n",
    "        combined_gp_dict = dict(nichenet_gp_dict)\n",
    "        combined_gp_dict.update(omnipath_gp_dict)\n",
    "        combined_gp_dict.update(mebocost_gp_dict)\n",
    "\n",
    "        # Filter and combine gene programs\n",
    "        combined_new_gp_dict = filter_and_combine_gp_dict_gps(\n",
    "            gp_dict=combined_gp_dict,\n",
    "            gp_filter_mode=gp_filter_mode,\n",
    "            combine_overlap_gps=combine_overlap_gps,\n",
    "            overlap_thresh_source_genes=overlap_thresh_source_genes,\n",
    "            overlap_thresh_target_genes=overlap_thresh_target_genes,\n",
    "            overlap_thresh_genes=overlap_thresh_genes,\n",
    "            verbose=True)\n",
    "\n",
    "        mlflow.log_param(\"nichenet_keep_target_ratio\", nichenet_keep_target_ratio)\n",
    "        mlflow.log_param(\"omnipath_min_curation_effort\", omnipath_min_curation_effort)\n",
    "        mlflow.log_param(\"gp_filter_mode\", gp_filter_mode)\n",
    "        mlflow.log_param(\"combine_overlap_gps\", combine_overlap_gps)\n",
    "        mlflow.log_param(\"overlap_thresh_source_genes\", overlap_thresh_source_genes)\n",
    "        mlflow.log_param(\"overlap_thresh_target_genes\", overlap_thresh_target_genes)\n",
    "        mlflow.log_param(\"overlap_thresh_genes\", overlap_thresh_genes)\n",
    "        print(f\"Number of gene programs before filtering and combining: {len(combined_gp_dict)}.\")\n",
    "        print(f\"Number of gene programs after filtering and combining: {len(combined_new_gp_dict)}.\")\n",
    "        print(\"\")\n",
    "\n",
    "    # Loop `n_iters` times through combination of hyperparams \n",
    "    iters = range(n_iters)\n",
    "    hyperparams, hyperparam_values = zip(*hyperparam_option_dict.items())\n",
    "    for hyperparam_comb in itertools.product(*hyperparam_values, iters):\n",
    "        hyperparam_dict = {}\n",
    "        for hyperparam, hyperparam_value in zip(hyperparams, hyperparam_comb):\n",
    "            hyperparam_dict[hyperparam] = hyperparam_value\n",
    "    \n",
    "        experiment = mlflow.set_experiment(experiment_name)\n",
    "\n",
    "        print(\"--- DATASET ---\")\n",
    "        print(f\"Using dataset {dataset}.\")\n",
    "        mlflow.log_param(\"dataset\", dataset)\n",
    "        adata = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "        n_nodes = adata.layers[\"counts\"].shape[0]\n",
    "        n_genes = adata.layers[\"counts\"].shape[1]\n",
    "        print(f\"Number of nodes (cells): {n_nodes}\")\n",
    "        print(f\"Number of node features (genes): {n_genes}\")\n",
    "        mlflow.log_param(\"n_nodes\", n_nodes)\n",
    "        mlflow.log_param(\"n_genes\", n_genes)\n",
    "\n",
    "        if gp_mask == \"fc\":\n",
    "            if hyperparam_dict[\"node_label_method\"] == \"self\":\n",
    "                n_output = len(adata.var)\n",
    "                adata.varm[gp_targets_mask_key] = np.ones((hyperparam_dict[\"n_latent_fc_gps\"], n_output))\n",
    "            elif hyperparam_dict[\"node_label_method\"] != \"self\":\n",
    "                n_output = len(adata.var) * 2\n",
    "                adata.varm[gp_targets_mask_key] = np.ones((hyperparam_dict[\"n_latent_fc_gps\"], int(n_output / 2)))\n",
    "                adata.varm[gp_sources_mask_key] = np.ones((hyperparam_dict[\"n_latent_fc_gps\"], int(n_output / 2)))\n",
    "            adata.uns[gp_names_key] = np.array([f\"FC_GP_{i}\" for i in range(hyperparam_dict[\"n_latent_fc_gps\"])])\n",
    "            n_hidden_encoder = int(hyperparam_dict[\"n_latent_fc_gps\"]/2)\n",
    "        elif gp_mask == \"combined_priors\":\n",
    "            min_source_genes_per_gp = 1\n",
    "            min_target_genes_per_gp = 1\n",
    "            mlflow.log_param(\"min_source_genes_per_gp\", min_source_genes_per_gp)\n",
    "            mlflow.log_param(\"min_target_genes_per_gp\", min_target_genes_per_gp)            \n",
    "            # Add the gene program dictionary as binary masks to the adata for model training\n",
    "            add_gps_from_gp_dict_to_adata(\n",
    "                gp_dict=combined_new_gp_dict,\n",
    "                adata=adata,\n",
    "                genes_uppercase=True,\n",
    "                gp_targets_mask_key=gp_targets_mask_key,\n",
    "                gp_sources_mask_key=gp_sources_mask_key,\n",
    "                gp_names_key=gp_names_key,\n",
    "                min_genes_per_gp=1,\n",
    "                min_source_genes_per_gp=min_source_genes_per_gp,\n",
    "                min_target_genes_per_gp=min_target_genes_per_gp,\n",
    "                max_genes_per_gp=None,\n",
    "                max_source_genes_per_gp=None,\n",
    "                max_target_genes_per_gp=None)\n",
    "            n_hidden_encoder = len(adata.uns[gp_names_key])\n",
    "        # Summarize gene programs\n",
    "        print(f\"Number of gene programs with probed genes: {len(adata.uns['autotalker_gp_names'])}.\")\n",
    "        print(f\"Example gene programs: {random.sample(list(adata.uns['autotalker_gp_names']), 5)}.\")\n",
    "        print(f\"Number of gene program target genes: {adata.varm['autotalker_gp_targets'].sum()}.\")\n",
    "        print(f\"Number of gene program source genes: {adata.varm['autotalker_gp_sources'].sum()}.\")\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"--- SPATIAL CONNECTIVITY ---\")\n",
    "        # Compute spatial neighborhood\n",
    "        sq.gr.spatial_neighbors(adata,\n",
    "                                coord_type=\"generic\",\n",
    "                                spatial_key=spatial_key,\n",
    "                                n_neighs=hyperparam_dict[\"n_neighs\"])\n",
    "        avg_edges_per_node = round(adata.obsp['spatial_connectivities'].sum(axis=0).mean(), 2)\n",
    "        print(f\"Average number of edges per node: {avg_edges_per_node}\")\n",
    "        n_edges = int(sp.triu(adata.obsp['spatial_connectivities'], k=1).sum())\n",
    "        print(f\"Number of total edges: {n_edges}\", sep=\"\")\n",
    "        mlflow.log_param(\"n_neighbors\", hyperparam_dict[\"n_neighs\"])\n",
    "        mlflow.log_param(\"n_edges\", n_edges)\n",
    "\n",
    "        # Initialize model\n",
    "        print(\"\")\n",
    "        model = Autotalker(adata,\n",
    "                           counts_key=counts_key,\n",
    "                           adj_key=adj_key,\n",
    "                           gp_names_key=gp_names_key,\n",
    "                           active_gp_names_key=active_gp_names_key,\n",
    "                           gp_targets_mask_key=gp_targets_mask_key,\n",
    "                           gp_sources_mask_key=gp_sources_mask_key,\n",
    "                           latent_key=latent_key,\n",
    "                           include_edge_recon_loss=hyperparam_dict[\"include_edge_recon_loss\"],\n",
    "                           include_gene_expr_recon_loss=hyperparam_dict[\"include_gene_expr_recon_loss\"],\n",
    "                           gene_expr_recon_dist=hyperparam_dict[\"gene_expr_recon_dist\"],\n",
    "                           node_label_method=hyperparam_dict[\"node_label_method\"],\n",
    "                           active_gp_thresh_ratio=hyperparam_dict[\"active_gp_thresh_ratio\"],\n",
    "                           n_hidden_encoder=n_hidden_encoder,\n",
    "                           conv_layer_encoder=hyperparam_dict[\"conv_layer_encoder\"],\n",
    "                           encoder_n_attention_heads=hyperparam_dict[\"encoder_n_attention_heads\"],\n",
    "                           n_addon_gps=hyperparam_dict[\"n_addon_gps\"])\n",
    "\n",
    "        # Train model\n",
    "        print(\"\")\n",
    "        model.train(n_epochs=hyperparam_dict[\"n_epochs\"],\n",
    "                    n_epochs_all_gps=hyperparam_dict[\"n_epochs_all_gps\"],\n",
    "                    lr=hyperparam_dict[\"lr\"],\n",
    "                    lambda_edge_recon=hyperparam_dict[\"lambda_edge_recon\"],\n",
    "                    lambda_gene_expr_recon=hyperparam_dict[\"lambda_gene_expr_recon\"],\n",
    "                    lambda_group_lasso=hyperparam_dict[\"lambda_group_lasso\"],\n",
    "                    lambda_l1_addon=hyperparam_dict[\"lambda_l1_addon\"],\n",
    "                    mlflow_experiment_id=experiment.experiment_id,\n",
    "                    verbose=True)\n",
    "\n",
    "        print(\"\")\n",
    "        # Benchmark model\n",
    "        benchmark_dict = model.run_benchmarks(\n",
    "            adata=model.adata,\n",
    "            cell_type_key=cell_type_key,\n",
    "            spatial_key=spatial_key,\n",
    "            spatial_knng_key=\"autotalker_spatial_knng\",\n",
    "            latent_knng_key=\"autotalker_latent_knng\",\n",
    "            n_neighbors=hyperparam_dict[\"n_neighs\"],\n",
    "            seed=random_seed,\n",
    "            mlflow_experiment_id=experiment.experiment_id)\n",
    "        print(\"--- BENCHMARKING RESULTS ---\")\n",
    "        print(benchmark_dict)\n",
    "\n",
    "        if save_model:\n",
    "            # Get time for timestamping saved artefacts\n",
    "            now = datetime.now()\n",
    "            current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")\n",
    "            \n",
    "            model.save(dir_path=f\"{model_artefacts_path}/{dataset}/benchmark_conv_layer_encoder/{current_timestamp}\",\n",
    "                       overwrite=True,\n",
    "                       save_adata=True,\n",
    "                       adata_file_name=f\"{dataset}.h5ad\")\n",
    "\n",
    "        mlflow.end_run()\n",
    "        print(\"--------------------\")\n",
    "        print(\"\")\n",
    "        print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b089dc00-0251-4131-861c-308489b66790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_benchmarking_metrics(fig_title,\n",
    "                              df,\n",
    "                              y_col_name,\n",
    "                              save_fig=False,\n",
    "                              save_dir=\"../figures\",\n",
    "                              file_name=\"benchmarking_metrics.png\"):\n",
    "    fig, axes = plt.subplots(3, 2, sharey=True, figsize=(10, 10))\n",
    "    fig.suptitle(fig_title)\n",
    "    \n",
    "    # Graph Connectivity Distance\n",
    "    sns.boxplot(data=df, ax=axes[0, 0], x=\"gcd\", y=y_col_name)\n",
    "    axes[0, 0].set_title(\"GCD\")\n",
    "\n",
    "    # Maximum Leiden Normalized Mutual Info\n",
    "    sns.boxplot(data=df, ax=axes[0, 1], x=\"mlnmi\", y=y_col_name)\n",
    "    axes[0, 1].set_title(\"MLNMI\")\n",
    "\n",
    "    # Cell-Type Affinity Distance\n",
    "    sns.boxplot(data=df, ax=axes[1, 0], x=\"cad\", y=y_col_name)\n",
    "    axes[1, 0].set_title(\"CAD\")\n",
    "\n",
    "    # Average Absolute Log Relative Cell-Type Local Inverse Simpson's Index\n",
    "    sns.boxplot(data=df, ax=axes[1, 1], x=\"arclisi\", y=y_col_name)\n",
    "    axes[1, 1].set_title(\"ARCLISI\")\n",
    "\n",
    "    # Cell Classification Accuracy\n",
    "    sns.boxplot(data=df, ax=axes[2, 0], x=\"cca\", y=y_col_name)\n",
    "    axes[2, 0].set_title(\"CCA\")\n",
    "\n",
    "    # Gene Expression Regression Mean Squared Error\n",
    "    sns.boxplot(data=df, ax=axes[2, 1], x=\"germse\", y=y_col_name)\n",
    "    axes[2, 1].set_title(\"GERMSE\")\n",
    "\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1,\n",
    "                        right=0.9,\n",
    "                        top=0.9,\n",
    "                        wspace=0.2,\n",
    "                        hspace=0.4)\n",
    "    if save_fig:\n",
    "        # Get time for timestamping saved artefacts\n",
    "        now = datetime.now()\n",
    "        current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")\n",
    "\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        plt.savefig(f\"{save_dir}/{file_name}_{current_timestamp}.png\",\n",
    "                    bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7332dc1-413d-4e64-9161-38115e91c450",
   "metadata": {},
   "source": [
    "## 2. Benchmarking Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8044850-0777-410b-8e1d-a4e8946ac5f7",
   "metadata": {},
   "source": [
    "### 3.1. Benchmark Number of Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d6682-9985-4f2a-87b8-2623bb928b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GP MASK ---\n",
      "Using 'combined_priors' GP mask.\n",
      "Downloading NicheNet ligand target potential matrix from the web. This might take a while...\n"
     ]
    }
   ],
   "source": [
    "hyperparam_option_dict = {}\n",
    "hyperparam_option_dict[\"n_neighs\"] = [4, 8, 16, 32, 64]\n",
    "hyperparam_option_dict[\"include_edge_recon_loss\"] = [True]\n",
    "hyperparam_option_dict[\"include_gene_expr_recon_loss\"] = [True]\n",
    "hyperparam_option_dict[\"active_gp_thresh_ratio\"] = [\"nb\"]\n",
    "hyperparam_option_dict[\"node_label_method\"] = [\"one-hop-norm\"]\n",
    "hyperparam_option_dict[\"active_gp_thresh_ratio\"] = [0.]\n",
    "hyperparam_option_dict[\"conv_layer_encoder\"] = [\"gcnconv\"]\n",
    "hyperparam_option_dict[\"encoder_n_attention_heads\"] = [1]\n",
    "hyperparam_option_dict[\"n_addon_gps\"] = [0]\n",
    "hyperparam_option_dict[\"n_epochs\"] = [10]\n",
    "hyperparam_option_dict[\"n_epochs_all_gps\"] = [2]\n",
    "hyperparam_option_dict[\"lr\"] = [0.01]\n",
    "hyperparam_option_dict[\"lambda_edge_recon\"] = [1.]\n",
    "hyperparam_option_dict[\"lambda_gene_expr_recon\"] = [1.]\n",
    "hyperparam_option_dict[\"lambda_group_lasso\"] = [0]\n",
    "hyperparam_option_dict[\"lambda_l1_addon\"] = [0]\n",
    "\n",
    "run_hyperparam_benchmarking(dataset=dataset,\n",
    "                            hyperparam_option_dict=hyperparam_option_dict,\n",
    "                            n_iters=5,\n",
    "                            experiment_name=\"benchmark_n_neighs\",\n",
    "                            gp_mask=\"combined_priors\",\n",
    "                            save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2ee9a1-30ad-45c6-8e1d-6b982ffa736c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "6df974f1-713b-4f6e-9ce3-4546188c24f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "hyperparams = {}\n",
    "hyperparams[\"n_neighs\"] = [4, 8, 16, 32, 64]\n",
    "hyperparams[\"n_latent_fc_gps\"] = [32, 64, 128, 256, 512] \n",
    "# n_neighs=64 combined with n_latent_fc_gps=512 -> OOM \n",
    "hyperparams[\"include_edge_recon_loss\"] = [True, False]\n",
    "hyperparams[\"lambda_edge_recon\"] = [None]\n",
    "hyperparams[\"include_gene_expr_recon_loss\"] = [True, False]\n",
    "hyperparams[\"lambda_gene_expr_recon\"] = [1.]\n",
    "hyperparams[\"node_label_method\"] = [\"self\"]\n",
    "hyperparams[\"gene_expr_recon_dist\"] = [\"nb\"]\n",
    "hyperparams[\"conv_layer_encoder\"] = [\"gcnconv\"]\n",
    "n_epochs = 10\n",
    "lr = 0.01\n",
    "\n",
    "# Loop through combination of hyperparams\n",
    "iters = range(1)\n",
    "keys, values = zip(*hyperparams.items())\n",
    "for hyperparam_config in itertools.product(*values, iters):\n",
    "    \n",
    "    n_neighs = hyperparam_config[0]\n",
    "    n_latent_fc_gps = hyperparam_config[1]\n",
    "    include_edge_recon_loss = hyperparam_config[2]\n",
    "    lambda_edge_recon = hyperparam_config[3]\n",
    "    include_gene_expr_recon_loss = hyperparam_config[4]\n",
    "    lambda_gene_expr_recon = hyperparam_config[5]\n",
    "    node_label_method = hyperparam_config[6]\n",
    "    gene_expr_recon_dist = hyperparam_config[7]\n",
    "    conv_layer_encoder = hyperparam_config[8]\n",
    "    \n",
    "    experiment = mlflow.set_experiment(\"benchmark_loss_inclusions\")\n",
    "    \n",
    "    # Get time for timestamping saved artefacts\n",
    "    now = datetime.now()\n",
    "    current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")\n",
    "    \n",
    "    print(\"--- DATASET ---\")\n",
    "    adata = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "    print(f\"Using dataset {dataset}.\")\n",
    "    mlflow.log_param(\"dataset\", dataset)\n",
    "    n_nodes = adata.layers[\"counts\"].shape[0]\n",
    "    n_genes = adata.layers[\"counts\"].shape[1]\n",
    "    print(f\"Number of nodes (cells): {n_nodes}\")\n",
    "    print(f\"Number of node features (genes): {n_genes}\")\n",
    "    mlflow.log_param(\"n_nodes\", n_nodes)\n",
    "    mlflow.log_param(\"n_genes\", n_genes)\n",
    "\n",
    "    # Create fully-connected mask that allows all latent dims to reconstruct all genes\n",
    "    n_output = len(adata.var)\n",
    "    gp_targets_mask = np.ones((n_latent_fc_gps, n_output))\n",
    "    adata.uns[gp_names_key] = np.array([f\"FC_GP_{i}\" for i in range(n_latent_fc_gps)])\n",
    "\n",
    "    # Determine dimensionality of hidden encoder\n",
    "    n_hidden_encoder = int(n_latent_fc_gps/2)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"--- SPATIAL CONNECTIVITIES STATS ---\")\n",
    "    # Compute spatial neighborhood\n",
    "    sq.gr.spatial_neighbors(adata,\n",
    "                            coord_type=\"generic\",\n",
    "                            spatial_key=spatial_key,\n",
    "                            n_neighs=n_neighs)\n",
    "    avg_edges_per_node = round(adata.obsp['spatial_connectivities'].sum(axis=0).mean(), 2)\n",
    "    print(f\"Average number of edges per node: {avg_edges_per_node}\")\n",
    "    n_edges = int(sp.triu(adata.obsp['spatial_connectivities'], k=1).sum())\n",
    "    print(f\"Number of total edges: {n_edges}\", sep=\"\")\n",
    "    mlflow.log_param(\"n_neighbors\", n_neighs)\n",
    "    mlflow.log_param(\"n_edges\", n_edges)\n",
    "\n",
    "    print(\"\")\n",
    "    # Initialize model\n",
    "    model = Autotalker(adata,\n",
    "                       counts_key=counts_key,\n",
    "                       adj_key=adj_key,\n",
    "                       gp_names_key=gp_names_key,\n",
    "                       active_gp_names_key=active_gp_names_key,\n",
    "                       latent_key=latent_key,\n",
    "                       include_edge_recon_loss=include_edge_recon_loss,\n",
    "                       include_gene_expr_recon_loss=include_gene_expr_recon_loss,\n",
    "                       gene_expr_recon_dist=gene_expr_recon_dist,\n",
    "                       node_label_method=node_label_method,\n",
    "                       n_hidden_encoder=n_hidden_encoder,\n",
    "                       conv_layer_encoder=conv_layer_encoder,\n",
    "                       gp_targets_mask=gp_targets_mask,\n",
    "                       gp_sources_mask=None,\n",
    "                       n_addon_gps=0)\n",
    "    \n",
    "    print(\"\")\n",
    "    # Train model\n",
    "    model.train(n_epochs=n_epochs,\n",
    "                lr=lr,\n",
    "                lambda_edge_recon=lambda_edge_recon,\n",
    "                lambda_gene_expr_recon=lambda_gene_expr_recon,\n",
    "                mlflow_experiment_id=experiment.experiment_id,\n",
    "                verbose=True)\n",
    "    \n",
    "    print(\"\")\n",
    "    # Benchmark model\n",
    "    benchmark_dict = model.run_benchmarks(\n",
    "        adata=model.adata,\n",
    "        cell_type_key=cell_type_key,\n",
    "        spatial_key=spatial_key,\n",
    "        spatial_knng_key=\"autotalker_spatial_knng\",\n",
    "        latent_knng_key=\"autotalker_latent_knng\",\n",
    "        n_neighbors=n_neighs,\n",
    "        seed=random_seed,\n",
    "        mlflow_experiment_id=experiment.experiment_id)\n",
    "    print(\"--- BENCHMARKING RESULTS ---\")\n",
    "    print(benchmark_dict)\n",
    "    \n",
    "    print(\"--------------------\")\n",
    "    print(\"\")\n",
    "    print(\"--------------------\")\n",
    "    #model.save(dir_path=f\"{model_artefacts_path}/{dataset}/benchmark_loss_inclusions/{current_timestamp}\",\n",
    "    #           overwrite=True,\n",
    "    #           save_adata=True,\n",
    "    #           adata_file_name=f\"{dataset}.h5ad\")\n",
    "    \n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02518ca2-da07-48fc-ad67-b0f4d55cd59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"benchmark_loss_inclusions\"\n",
    "\n",
    "runs = mlflow.search_runs(experiment_names=[experiment_name],\n",
    "                          output_format=\"list\")\n",
    "\n",
    "data = []\n",
    "for run in runs:\n",
    "    data.append({**run.data.metrics, **run.data.params})\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f72e3-1e55-4400-81df-46a67d5647c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recon_loss_inclusion(row):  \n",
    "    if row[\"include_edge_recon_loss_\"] == \"True\" and row[\"include_gene_expr_recon_loss_\"] == \"True\":\n",
    "        return \"edge_+_gene_expr\"\n",
    "    elif row[\"include_edge_recon_loss_\"] == \"True\" and row[\"include_gene_expr_recon_loss_\"] == \"False\":\n",
    "        return \"only_edge\"\n",
    "    elif row[\"include_edge_recon_loss_\"] == \"False\" and row[\"include_gene_expr_recon_loss_\"] == \"True\":\n",
    "        return \"only_gene_expr\"\n",
    "    return \"none\"\n",
    "\n",
    "df[\"recon_loss_inclusions\"] = df.apply(lambda row: get_recon_loss_inclusion(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ac8366-b8dc-4916-8155-586975b64d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, sharey=True, figsize=(10, 10))\n",
    "fig.suptitle(\"Reconstruction Loss Inclusion Benchmarking Metrics\")\n",
    "\n",
    "# Graph Connectivity Distance\n",
    "sns.boxplot(data=df, ax=axes[0, 0], x=\"gcd\", y=\"recon_loss_inclusions\")\n",
    "axes[0, 0].set_title(\"GCD\")\n",
    "\n",
    "# Maximum Leiden Normalized Mutual Info\n",
    "sns.boxplot(data=df, ax=axes[0, 1], x=\"mlnmi\", y=\"recon_loss_inclusions\")\n",
    "axes[0, 1].set_title(\"MLNMI\")\n",
    "\n",
    "# Cell-Type Affinity Distance\n",
    "sns.boxplot(data=df, ax=axes[1, 0], x=\"cad\", y=\"recon_loss_inclusions\")\n",
    "axes[1, 0].set_title(\"CAD\")\n",
    "\n",
    "# Average Absolute Log Relative Cell-Type Local Inverse Simpson's Index\n",
    "sns.boxplot(data=df, ax=axes[1, 1], x=\"arclisi\", y=\"recon_loss_inclusions\")\n",
    "axes[1, 1].set_title(\"ARCLISI\")\n",
    "\n",
    "# Cell Classification Accuracy\n",
    "sns.boxplot(data=df, ax=axes[2, 0], x=\"cca\", y=\"recon_loss_inclusions\")\n",
    "axes[2, 0].set_title(\"CCA\")\n",
    "\n",
    "# Gene Expression Regression Mean Squared Error\n",
    "sns.boxplot(data=df, ax=axes[2, 1], x=\"germse\", y=\"recon_loss_inclusions\")\n",
    "axes[2, 1].set_title(\"GERMSE\")\n",
    "\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1,\n",
    "                    right=0.9,\n",
    "                    top=0.9,\n",
    "                    wspace=0.2,\n",
    "                    hspace=0.4)\n",
    "\n",
    "# Get time for timestamping saved artefacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")\n",
    "\n",
    "os.makedirs(f\"{figure_path}/{dataset}\", exist_ok=True)\n",
    "plt.savefig(f\"{figure_path}/{dataset}/benchmark_loss_inclusions_{current_timestamp}.png\",\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b1766-daa3-4445-bafc-edcb22a66cce",
   "metadata": {},
   "source": [
    "### 3.2. Benchmark Gene Expression Reconstruction Distribution with FC GPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e27bc3c-8c18-4e35-a6ce-efabb18de1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {}\n",
    "hyperparams[\"n_neighs\"] = [2] # [2, 4, 8, 16]\n",
    "hyperparams[\"n_latent_fc_gps\"] = [32, 64, 128, 256, 512] \n",
    "hyperparams[\"include_edge_recon_loss\"] = [True]\n",
    "hyperparams[\"lambda_edge_recon\"] = [None]\n",
    "hyperparams[\"include_gene_expr_recon_loss\"] = [True]\n",
    "hyperparams[\"lambda_gene_expr_recon\"] = [1.]\n",
    "hyperparams[\"node_label_method\"] = [\"self\"]\n",
    "hyperparams[\"gene_expr_recon_dist\"] = [\"nb\", \"zinb\"] # <--- benchmark\n",
    "hyperparams[\"conv_layer_encoder\"] = [\"gcnconv\"]\n",
    "n_epochs = 10\n",
    "lr = 0.01\n",
    "\n",
    "# Loop through combination of hyperparams\n",
    "iters = range(1)\n",
    "keys, values = zip(*hyperparams.items())\n",
    "for hyperparam_config in itertools.product(*values, iters):\n",
    "    \n",
    "    n_neighs = hyperparam_dict[\"n_neighs\"]\n",
    "    n_latent_fc_gps = hyperparam_dict[\"n_neighs\"]\n",
    "    include_edge_recon_loss = hyperparam_dict[\"n_neighs\"]\n",
    "    lambda_edge_recon = hyperparam_dict[\"n_neighs\"]\n",
    "    include_gene_expr_recon_loss = hyperparam_dict[\"n_neighs\"]\n",
    "    lambda_gene_expr_recon = hyperparam_dict[\"n_neighs\"]\n",
    "    node_label_method = hyperparam_dict[\"n_neighs\"]\n",
    "    gene_expr_recon_dist = hyperparam_dict[\"n_neighs\"]\n",
    "    conv_layer_encoder = hyperparam_dict[\"n_neighs\"]\n",
    "    \n",
    "    experiment = mlflow.set_experiment(\"benchmark_gene_expr_recon_dist\")\n",
    "    \n",
    "    print(\"--- DATASET ---\")\n",
    "    adata = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "    print(f\"Using dataset {dataset}.\")\n",
    "    mlflow.log_param(\"dataset\", dataset)\n",
    "    n_nodes = adata.layers[\"counts\"].shape[0]\n",
    "    n_genes = adata.layers[\"counts\"].shape[1]\n",
    "    print(f\"Number of nodes (cells): {n_nodes}\")\n",
    "    print(f\"Number of node features (genes): {n_genes}\")\n",
    "    mlflow.log_param(\"n_nodes\", n_nodes)\n",
    "    mlflow.log_param(\"n_genes\", n_genes)\n",
    "\n",
    "    # Create fully-connected mask that allows all latent dims to reconstruct all genes\n",
    "    if node_label_method == \"self\":\n",
    "        n_output = len(adata.var)\n",
    "        gp_targets_mask = np.ones((n_latent_fc_gps, n_output))\n",
    "    elif node_label_method != \"self\":\n",
    "        n_output = len(adata.var) * 2\n",
    "        gp_targets_mask = np.ones((n_latent_fc_gps, int(n_output / 2)))\n",
    "        gp_sources_mask = np.ones((n_latent_fc_gps, int(n_output / 2)))\n",
    "    adata.uns[gp_names_key] = np.array([f\"FC_GP_{i}\" for i in range(n_latent_fc_gps)])\n",
    "\n",
    "    # Determine dimensionality of hidden encoder\n",
    "    n_hidden_encoder = int(n_latent_fc_gps/2)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"--- SPATIAL CONNECTIVITIES STATS ---\")\n",
    "    # Compute spatial neighborhood\n",
    "    sq.gr.spatial_neighbors(adata,\n",
    "                            coord_type=\"generic\",\n",
    "                            spatial_key=spatial_key,\n",
    "                            n_neighs=n_neighs)\n",
    "    avg_edges_per_node = round(adata.obsp['spatial_connectivities'].sum(axis=0).mean(), 2)\n",
    "    print(f\"Average number of edges per node: {avg_edges_per_node}\")\n",
    "    n_edges = int(sp.triu(adata.obsp['spatial_connectivities'], k=1).sum())\n",
    "    print(f\"Number of total edges: {n_edges}\", sep=\"\")\n",
    "    mlflow.log_param(\"n_neighbors\", n_neighs)\n",
    "    mlflow.log_param(\"n_edges\", n_edges)\n",
    "\n",
    "    print(\"\")\n",
    "    # Initialize model\n",
    "    model = Autotalker(adata,\n",
    "                       counts_key=counts_key,\n",
    "                       adj_key=adj_key,\n",
    "                       gp_names_key=gp_names_key,\n",
    "                       active_gp_names_key=active_gp_names_key,\n",
    "                       latent_key=latent_key,\n",
    "                       include_edge_recon_loss=include_edge_recon_loss,\n",
    "                       include_gene_expr_recon_loss=include_gene_expr_recon_loss,\n",
    "                       gene_expr_recon_dist=gene_expr_recon_dist,\n",
    "                       node_label_method=node_label_method,\n",
    "                       n_hidden_encoder=n_hidden_encoder,\n",
    "                       conv_layer_encoder=conv_layer_encoder,\n",
    "                       gp_targets_mask=gp_targets_mask,\n",
    "                       gp_sources_mask=(None if node_label_method == \"self\" else gp_sources_mask),\n",
    "                       n_addon_gps=0)\n",
    "    \n",
    "    print(\"\")\n",
    "    # Train model\n",
    "    model.train(n_epochs=n_epochs,\n",
    "                lr=lr,\n",
    "                lambda_edge_recon=lambda_edge_recon,\n",
    "                lambda_gene_expr_recon=lambda_gene_expr_recon,\n",
    "                mlflow_experiment_id=experiment.experiment_id,\n",
    "                verbose=True)\n",
    "    \n",
    "    print(\"\")\n",
    "    # Benchmark model\n",
    "    benchmark_dict = model.run_benchmarks(\n",
    "        adata=model.adata,\n",
    "        cell_type_key=cell_type_key,\n",
    "        spatial_key=spatial_key,\n",
    "        spatial_knng_key=\"autotalker_spatial_knng\",\n",
    "        latent_knng_key=\"autotalker_latent_knng\",\n",
    "        n_neighbors=n_neighs,\n",
    "        seed=random_seed,\n",
    "        mlflow_experiment_id=experiment.experiment_id)\n",
    "    print(\"--- BENCHMARKING RESULTS ---\")\n",
    "    print(benchmark_dict)\n",
    "    \n",
    "    # Get time for timestamping saved artefacts\n",
    "    now = datetime.now()\n",
    "    current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")\n",
    "    #model.save(dir_path=f\"{model_artefacts_path}/{dataset}/benchmark_conv_layer_encoder/{current_timestamp}\",\n",
    "    #           overwrite=True,\n",
    "    #           save_adata=True,\n",
    "    #           adata_file_name=f\"{dataset}.h5ad\")\n",
    "    print(\"--------------------\")\n",
    "    print(\"\")\n",
    "    print(\"--------------------\")\n",
    "    \n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf67cd0-14dd-4add-a59f-fb3ee31747d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"benchmark_gene_expr_recon_dist\"\n",
    "\n",
    "runs = mlflow.search_runs(experiment_names=[experiment_name],\n",
    "                          output_format=\"list\")\n",
    "\n",
    "data = []\n",
    "for run in runs:\n",
    "    data.append({**run.data.metrics, **run.data.params})\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb80fda-39c2-4111-a304-4f2dc89bb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_benchmarking_metrics(\n",
    "    fig_title=\"Gene Expression Reconstruction Distribution Benchmarking Metrics\",\n",
    "    df=df,\n",
    "    y_col_name=\"gene_expr_recon_dist_\",\n",
    "    save_fig=False,\n",
    "    save_dir=figure_path,\n",
    "    file_name=\"benchmarking_gene_expr_recon_dist.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e77ea7-4fe3-4f16-af9d-beffbd33ab2c",
   "metadata": {},
   "source": [
    "### 3.3. Benchmark Conv Layer of Encoder & Node Label Method with FC GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284da77d-3238-4cf3-a7a8-3c232569fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {}\n",
    "hyperparams[\"n_neighs\"] = [16] # [2, 4, 8, 16]\n",
    "hyperparams[\"n_latent_fc_gps\"] = [32, 64, 128] \n",
    "hyperparams[\"include_edge_recon_loss\"] = [True]\n",
    "hyperparams[\"lambda_edge_recon\"] = [None]\n",
    "hyperparams[\"include_gene_expr_recon_loss\"] = [True]\n",
    "hyperparams[\"lambda_gene_expr_recon\"] = [1.]\n",
    "hyperparams[\"node_label_method\"] = [\"self\",\n",
    "                                    \"one-hop-sum\",\n",
    "                                    \"one-hop-norm\",\n",
    "                                    \"one-hop-attention\"] # <--- benchmark\n",
    "hyperparams[\"gene_expr_recon_dist\"] = [\"nb\"]\n",
    "hyperparams[\"conv_layer_encoder\"] = [\"gcnconv\", \"gatv2conv\"] # <--- benchmark\n",
    "n_epochs = 10\n",
    "lr = 0.01\n",
    "\n",
    "# Loop through combination of hyperparams\n",
    "iters = range(1)\n",
    "keys, values = zip(*hyperparams.items())\n",
    "for hyperparam_config in itertools.product(*values, iters):\n",
    "    \n",
    "    n_neighs = hyperparam_config[0]\n",
    "    n_latent_fc_gps = hyperparam_config[1]\n",
    "    include_edge_recon_loss = hyperparam_config[2]\n",
    "    lambda_edge_recon = hyperparam_config[3]\n",
    "    include_gene_expr_recon_loss = hyperparam_config[4]\n",
    "    lambda_gene_expr_recon = hyperparam_config[5]\n",
    "    node_label_method = hyperparam_config[6]\n",
    "    gene_expr_recon_dist = hyperparam_config[7]\n",
    "    conv_layer_encoder = hyperparam_config[8]\n",
    "    \n",
    "    experiment = mlflow.set_experiment(\"benchmark_conv_layer_and_node_label_method\")\n",
    "    \n",
    "    print(\"--- DATASET ---\")\n",
    "    adata = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "    print(f\"Using dataset {dataset}.\")\n",
    "    mlflow.log_param(\"dataset\", dataset)\n",
    "    n_nodes = adata.layers[\"counts\"].shape[0]\n",
    "    n_genes = adata.layers[\"counts\"].shape[1]\n",
    "    print(f\"Number of nodes (cells): {n_nodes}\")\n",
    "    print(f\"Number of node features (genes): {n_genes}\")\n",
    "    mlflow.log_param(\"n_nodes\", n_nodes)\n",
    "    mlflow.log_param(\"n_genes\", n_genes)\n",
    "\n",
    "    # Create fully-connected mask that allows all latent dims to reconstruct all genes\n",
    "    if node_label_method == \"self\":\n",
    "        n_output = len(adata.var)\n",
    "        gp_targets_mask = np.ones((n_latent_fc_gps, n_output))\n",
    "    elif node_label_method != \"self\":\n",
    "        n_output = len(adata.var) * 2\n",
    "        gp_targets_mask = np.ones((n_latent_fc_gps, int(n_output / 2)))\n",
    "        gp_sources_mask = np.ones((n_latent_fc_gps, int(n_output / 2)))\n",
    "    adata.uns[gp_names_key] = np.array([f\"FC_GP_{i}\" for i in range(n_latent_fc_gps)])\n",
    "\n",
    "    # Determine dimensionality of hidden encoder\n",
    "    n_hidden_encoder = int(n_latent_fc_gps/2)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"--- SPATIAL CONNECTIVITIES STATS ---\")\n",
    "    # Compute spatial neighborhood\n",
    "    sq.gr.spatial_neighbors(adata,\n",
    "                            coord_type=\"generic\",\n",
    "                            spatial_key=spatial_key,\n",
    "                            n_neighs=n_neighs)\n",
    "    avg_edges_per_node = round(adata.obsp['spatial_connectivities'].sum(axis=0).mean(), 2)\n",
    "    print(f\"Average number of edges per node: {avg_edges_per_node}\")\n",
    "    n_edges = int(sp.triu(adata.obsp['spatial_connectivities'], k=1).sum())\n",
    "    print(f\"Number of total edges: {n_edges}\", sep=\"\")\n",
    "    mlflow.log_param(\"n_neighbors\", n_neighs)\n",
    "    mlflow.log_param(\"n_edges\", n_edges)\n",
    "\n",
    "    print(\"\")\n",
    "    # Initialize model\n",
    "    model = Autotalker(adata,\n",
    "                       counts_key=counts_key,\n",
    "                       adj_key=adj_key,\n",
    "                       gp_names_key=gp_names_key,\n",
    "                       active_gp_names_key=active_gp_names_key,\n",
    "                       latent_key=latent_key,\n",
    "                       include_edge_recon_loss=include_edge_recon_loss,\n",
    "                       include_gene_expr_recon_loss=include_gene_expr_recon_loss,\n",
    "                       gene_expr_recon_dist=gene_expr_recon_dist,\n",
    "                       node_label_method=node_label_method,\n",
    "                       n_hidden_encoder=n_hidden_encoder,\n",
    "                       conv_layer_encoder=conv_layer_encoder,\n",
    "                       gp_targets_mask=gp_targets_mask,\n",
    "                       gp_sources_mask=(None if node_label_method == \"self\" else gp_sources_mask),\n",
    "                       n_addon_gps=0)\n",
    "    \n",
    "    print(\"\")\n",
    "    # Train model\n",
    "    model.train(n_epochs=n_epochs,\n",
    "                lr=lr,\n",
    "                lambda_edge_recon=lambda_edge_recon,\n",
    "                lambda_gene_expr_recon=lambda_gene_expr_recon,\n",
    "                mlflow_experiment_id=experiment.experiment_id,\n",
    "                verbose=True)\n",
    "    \n",
    "    print(\"\")\n",
    "    # Benchmark model\n",
    "    benchmark_dict = model.run_benchmarks(\n",
    "        adata=model.adata,\n",
    "        cell_type_key=cell_type_key,\n",
    "        spatial_key=spatial_key,\n",
    "        spatial_knng_key=\"autotalker_spatial_knng\",\n",
    "        latent_knng_key=\"autotalker_latent_knng\",\n",
    "        n_neighbors=n_neighs,\n",
    "        seed=random_seed,\n",
    "        mlflow_experiment_id=experiment.experiment_id)\n",
    "    print(\"--- BENCHMARKING RESULTS ---\")\n",
    "    print(benchmark_dict)\n",
    "    \n",
    "    # Get time for timestamping saved artefacts\n",
    "    now = datetime.now()\n",
    "    current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")\n",
    "    #model.save(dir_path=f\"{model_artefacts_path}/{dataset}/benchmark_conv_layer_encoder/{current_timestamp}\",\n",
    "    #           overwrite=True,\n",
    "    #           save_adata=True,\n",
    "    #           adata_file_name=f\"{dataset}.h5ad\")\n",
    "    print(\"--------------------\")\n",
    "    print(\"\")\n",
    "    print(\"--------------------\")\n",
    "    \n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fee4ffc-61d2-4f6c-9643-4d7dbc2c7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {}\n",
    "hyperparams[\"n_neighs\"] = [4]\n",
    "hyperparams[\"n_latent_fc_gps\"] = [256, 512]\n",
    "# n_neighs=64 combined with n_latent_fc_gps=512 -> OOM \n",
    "hyperparams[\"include_edge_recon_loss\"] = [True]\n",
    "hyperparams[\"lambda_edge_recon\"] = [None]\n",
    "hyperparams[\"include_gene_expr_recon_loss\"] = [True]\n",
    "hyperparams[\"lambda_gene_expr_recon\"] = [1.]\n",
    "hyperparams[\"node_label_method\"] = [\"self\",\n",
    "                                    \"one-hop-sum\",\n",
    "                                    \"one-hop-norm\",\n",
    "                                    \"one-hop-attention\"]\n",
    "hyperparams[\"gene_expr_recon_dist\"] = [\"nb\",\n",
    "                                       \"zinb\"]\n",
    "n_epochs = 10\n",
    "lr = 0.01\n",
    "\n",
    "# Loop through combination of hyperparams\n",
    "iters = range(1)\n",
    "keys, values = zip(*hyperparams.items())\n",
    "for hyperparam_config in itertools.product(*values, iters):\n",
    "    \n",
    "    n_neighs = hyperparam_config[0]\n",
    "    n_latent_fc_gps = hyperparam_config[1]\n",
    "    include_edge_recon_loss = hyperparam_config[2]\n",
    "    lambda_edge_recon = hyperparam_config[3]\n",
    "    include_gene_expr_recon_loss = hyperparam_config[4]\n",
    "    lambda_gene_expr_recon = hyperparam_config[5]\n",
    "    node_label_method = hyperparam_config[6]\n",
    "    gene_expr_recon_dist = hyperparam_config[7]\n",
    "    \n",
    "    experiment = mlflow.set_experiment(\"benchmark_gene_expr_recon\")\n",
    "    \n",
    "    # Get time for timestamping saved artefacts\n",
    "    now = datetime.now()\n",
    "    current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")\n",
    "    \n",
    "    print(\"--- DATASET ---\")\n",
    "    adata = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "    print(f\"Using dataset {dataset}.\")\n",
    "    mlflow.log_param(\"dataset\", dataset)\n",
    "    n_nodes = adata.layers[\"counts\"].shape[0]\n",
    "    n_genes = adata.layers[\"counts\"].shape[1]\n",
    "    print(f\"Number of nodes (cells): {n_nodes}\")\n",
    "    print(f\"Number of node features (genes): {n_genes}\")\n",
    "    mlflow.log_param(\"n_nodes\", n_nodes)\n",
    "    mlflow.log_param(\"n_genes\", n_genes)\n",
    "\n",
    "    # Create fully-connected mask that allows all latent dims to reconstruct all genes\n",
    "    if node_label_method == \"self\":\n",
    "        n_output = len(adata.var)\n",
    "        gp_targets_mask = np.ones((n_latent_fc_gps, n_output))\n",
    "    elif node_label_method != \"self\":\n",
    "        n_output = len(adata.var) * 2\n",
    "        gp_targets_mask = np.ones((n_latent_fc_gps, int(n_output / 2)))\n",
    "        gp_sources_mask = np.ones((n_latent_fc_gps, int(n_output / 2)))\n",
    "    adata.uns[gp_names_key] = np.array([f\"FC_GP_{i}\" for i in range(n_latent_fc_gps)])\n",
    "\n",
    "    # Determine dimensionality of hidden encoder\n",
    "    n_hidden_encoder = int(n_latent_fc_gps/2)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"--- SPATIAL CONNECTIVITIES STATS ---\")\n",
    "    # Compute spatial neighborhood\n",
    "    sq.gr.spatial_neighbors(adata,\n",
    "                            coord_type=\"generic\",\n",
    "                            spatial_key=spatial_key,\n",
    "                            n_neighs=n_neighs)\n",
    "    avg_edges_per_node = round(adata.obsp['spatial_connectivities'].sum(axis=0).mean(), 2)\n",
    "    print(f\"Average number of edges per node: {avg_edges_per_node}\")\n",
    "    n_edges = int(sp.triu(adata.obsp['spatial_connectivities'], k=1).sum())\n",
    "    print(f\"Number of total edges: {n_edges}\", sep=\"\")\n",
    "    mlflow.log_param(\"n_neighbors\", n_neighs)\n",
    "    mlflow.log_param(\"n_edges\", n_edges)\n",
    "\n",
    "    print(\"\")\n",
    "    # Initialize model\n",
    "    model = Autotalker(adata,\n",
    "                       counts_key=counts_key,\n",
    "                       adj_key=adj_key,\n",
    "                       gp_names_key=gp_names_key,\n",
    "                       active_gp_names_key=active_gp_names_key,\n",
    "                       latent_key=latent_key,\n",
    "                       include_edge_recon_loss=include_edge_recon_loss,\n",
    "                       include_gene_expr_recon_loss=include_gene_expr_recon_loss,\n",
    "                       gene_expr_recon_dist=gene_expr_recon_dist,\n",
    "                       node_label_method=node_label_method,\n",
    "                       n_hidden_encoder=n_hidden_encoder,\n",
    "                       gp_targets_mask=gp_targets_mask,\n",
    "                       gp_sources_mask=(None if node_label_method == \"self\" else gp_sources_mask),\n",
    "                       n_addon_gps=0)\n",
    "    \n",
    "    print(\"\")\n",
    "    # Train model\n",
    "    model.train(n_epochs=n_epochs,\n",
    "                lr=lr,\n",
    "                lambda_edge_recon=lambda_edge_recon,\n",
    "                lambda_gene_expr_recon=lambda_gene_expr_recon,\n",
    "                mlflow_experiment_id=experiment.experiment_id,\n",
    "                verbose=True)\n",
    "    \n",
    "    print(\"\")\n",
    "    # Benchmark model\n",
    "    benchmark_dict = model.run_benchmarks(\n",
    "        adata=model.adata,\n",
    "        cell_type_key=cell_type_key,\n",
    "        spatial_key=spatial_key,\n",
    "        spatial_knng_key=\"autotalker_spatial_knng\",\n",
    "        latent_knng_key=\"autotalker_latent_knng\",\n",
    "        n_neighbors=n_neighs,\n",
    "        seed=random_seed,\n",
    "        mlflow_experiment_id=experiment.experiment_id)\n",
    "    print(\"--- BENCHMARKING RESULTS ---\")\n",
    "    print(benchmark_dict)\n",
    "    \n",
    "    print(\"--------------------\")\n",
    "    print(\"\")\n",
    "    print(\"--------------------\")\n",
    "    model.save(dir_path=f\"{model_artefacts_path}/{dataset}/benchmark_gene_expr_recon/{current_timestamp}\",\n",
    "               overwrite=True,\n",
    "               save_adata=True,\n",
    "               adata_file_name=f\"{dataset}.h5ad\")\n",
    "    \n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21de1201-cb25-4ddf-ad37-f32f9464b9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3795a834-2a06-407d-bb99-f663f940af06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac5bb40-469a-4356-bf10-29b2de01b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.adata.obsm['autotalker_latent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb9302-c377-4a96-a722-67b691f6ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_active_gps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8025a07-59f7-4725-bb34-d0c0104ab5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.active_gp_thresh_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a847f-9752-410f-a018-259f75b89f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "arclisi = compute_arclisi(model.adata, cell_type_key=\"celltype_mapped_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7777a926-4cef-4b04-b315-3ce6900efdb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5c208b-eab2-45b6-aa65-9fffc70400d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320c8492-f7c0-4e89-8117-4df98ab4f5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66051de5-1a2e-4a2a-a56e-545a84a3914c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
