{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b1daabf-c8e3-43d4-aa32-9789abcc8619",
   "metadata": {},
   "source": [
    "# Autotalker Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c325d921-2077-42b3-90a8-6f6c7dd928c5",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-LÃ³pez Lab\n",
    "- **Date of Creation:** 07.12.2022\n",
    "- **Date of Last Modification:** 09.01.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d464ebf-354f-4f61-8040-c3dcbcc893b9",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5631277-d8d2-4194-a376-280f4f149b7d",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d3297-0290-47c0-846f-705e74cdb3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd4925-7505-4d01-bf91-95b54bb8b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa3c6a-5a44-4cf1-84a3-5e514457cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import anndata as ad\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "import squidpy as sq\n",
    "\n",
    "from autotalker.models import Autotalker\n",
    "from autotalker.utils import (add_gps_from_gp_dict_to_adata,\n",
    "                              extract_gp_dict_from_mebocost_es_interactions,\n",
    "                              extract_gp_dict_from_nichenet_ligand_target_mx,\n",
    "                              extract_gp_dict_from_omnipath_lr_interactions,\n",
    "                              filter_and_combine_gp_dict_gps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f91f345-c297-47cb-8650-c6d9c60a8b7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4e6d9-239f-47c5-a30b-579b16d4c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "# Dataset\n",
    "dataset = \"squidpy_seqfish_mouse_organogenesis\"\n",
    "\n",
    "# Anndata Keys\n",
    "counts_key = \"counts\"\n",
    "cell_type_key = \"celltype_mapped_refined\"\n",
    "adj_key = \"spatial_connectivities\"\n",
    "spatial_key = \"spatial\"\n",
    "gp_names_key = \"autotalker_gp_names\"\n",
    "active_gp_names_key = \"autotalker_active_gp_names\"\n",
    "gp_targets_mask_key = \"autotalker_gp_targets\"\n",
    "gp_sources_mask_key = \"autotalker_gp_sources\"\n",
    "latent_key = \"autotalker_latent\"\n",
    "\n",
    "## Others\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6cf198-5909-4c1e-9805-5e494a63412d",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556ca35-3edf-4c42-84b3-2fe58d5fb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore future warnings and user warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b886225-6b6d-433c-b117-47b9a8f8091f",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36675337-808d-40a9-93fc-d6cfa9473f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "figure_path = \"../figures\"\n",
    "model_artifacts_path = \"../model_artifacts\"\n",
    "gp_data_folder_path = \"../datasets/gp_data\" # gene program data\n",
    "srt_data_folder_path = \"../datasets/srt_data\" # spatially resolved transcriptomics data\n",
    "srt_data_gold_folder_path = f\"{srt_data_folder_path}/gold\"\n",
    "nichenet_ligand_target_mx_file_path = gp_data_folder_path + \"/nichenet_ligand_target_matrix.csv\"\n",
    "omnipath_lr_interactions_file_path = gp_data_folder_path + \"/omnipath_lr_interactions.csv\"\n",
    "\n",
    "# Create required directories\n",
    "os.makedirs(figure_path, exist_ok=True)\n",
    "os.makedirs(model_artifacts_path, exist_ok=True)\n",
    "os.makedirs(gp_data_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc61ed2d-6ed4-45fa-8e74-b919d74000b5",
   "metadata": {},
   "source": [
    "### 1.5 Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa64ac5-8032-4aea-b36d-4379ffd38e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hyperparam_benchmarking(dataset,\n",
    "                                hyperparam_option_dict,\n",
    "                                n_iters,\n",
    "                                experiment_name,\n",
    "                                gp_mask=\"combined_priors\",\n",
    "                                save_figures=False,\n",
    "                                save_model=False):\n",
    "    # Read dataset\n",
    "    print(\"--- DATASET ---\")\n",
    "    print(f\"Using dataset {dataset}.\")\n",
    "    adata = ad.read_h5ad(f\"{srt_data_gold_folder_path}/{dataset}.h5ad\")\n",
    "    n_nodes = adata.layers[\"counts\"].shape[0]\n",
    "    n_genes = adata.layers[\"counts\"].shape[1]\n",
    "    print(f\"Number of nodes (cells): {n_nodes}.\")\n",
    "    print(f\"Number of node features (genes): {n_genes}.\")\n",
    "        \n",
    "    # Retrieve gene program mask\n",
    "    print(\"\")\n",
    "    print(\"--- GENE PROGRAMS ---\")\n",
    "    print(f\"Using '{gp_mask}' GP mask.\")\n",
    "    \n",
    "    if gp_mask == \"fc\":\n",
    "        n_output = len(adata.var) * 2\n",
    "        adata.varm[gp_targets_mask_key] = np.ones((int(len(adata.var) / 2), len(adata.var)))\n",
    "        adata.varm[gp_sources_mask_key] = np.ones((int(len(adata.var) / 2), len(adata.var)))\n",
    "        adata.uns[gp_names_key] = np.array([f\"FC_GP_{i}\" for i in range(int(len(adata.var) / 2))])\n",
    "    \n",
    "    elif gp_mask == \"combined_priors\":\n",
    "        nichenet_keep_target_ratio = 0.01\n",
    "        omnipath_min_curation_effort = 0\n",
    "        gp_filter_mode = \"subset\"\n",
    "        combine_overlap_gps = True\n",
    "        overlap_thresh_source_genes = 0.9\n",
    "        overlap_thresh_target_genes = 0.9\n",
    "        overlap_thresh_genes = 0.9\n",
    "        min_genes_per_gp = 1\n",
    "        min_source_genes_per_gp = 0\n",
    "        min_target_genes_per_gp = 0\n",
    "        \n",
    "        nichenet_gp_dict = extract_gp_dict_from_nichenet_ligand_target_mx(\n",
    "            keep_target_ratio=nichenet_keep_target_ratio,\n",
    "            load_from_disk=False,\n",
    "            save_to_disk=True,\n",
    "            file_path=nichenet_ligand_target_mx_file_path)\n",
    "        omnipath_gp_dict = extract_gp_dict_from_omnipath_lr_interactions(\n",
    "            min_curation_effort=omnipath_min_curation_effort,\n",
    "            load_from_disk=False,\n",
    "            save_to_disk=True,\n",
    "            file_path=omnipath_lr_interactions_file_path)\n",
    "        mebocost_gp_dict = extract_gp_dict_from_mebocost_es_interactions(\n",
    "            dir_path = \"../datasets/gp_data/metabolite_enzyme_sensor_gps/\",\n",
    "            species=\"mouse\",\n",
    "            genes_uppercase=True)\n",
    "        combined_gp_dict = dict(nichenet_gp_dict)\n",
    "        combined_gp_dict.update(omnipath_gp_dict)\n",
    "        combined_gp_dict.update(mebocost_gp_dict)\n",
    "\n",
    "        # Filter and combine gene programs\n",
    "        combined_new_gp_dict = filter_and_combine_gp_dict_gps(\n",
    "            gp_dict=combined_gp_dict,\n",
    "            gp_filter_mode=gp_filter_mode,\n",
    "            combine_overlap_gps=combine_overlap_gps,\n",
    "            overlap_thresh_source_genes=overlap_thresh_source_genes,\n",
    "            overlap_thresh_target_genes=overlap_thresh_target_genes,\n",
    "            overlap_thresh_genes=overlap_thresh_genes,\n",
    "            verbose=True)\n",
    "\n",
    "        print(f\"Number of gene programs before filtering and combining: {len(combined_gp_dict)}.\")\n",
    "        print(f\"Number of gene programs after filtering and combining: {len(combined_new_gp_dict)}.\")\n",
    "        \n",
    "        # Add the gene program dictionary as binary masks to the adata for model training\n",
    "        add_gps_from_gp_dict_to_adata(\n",
    "            gp_dict=combined_new_gp_dict,\n",
    "            adata=adata,\n",
    "            genes_uppercase=True,\n",
    "            gp_targets_mask_key=gp_targets_mask_key,\n",
    "            gp_sources_mask_key=gp_sources_mask_key,\n",
    "            gp_names_key=gp_names_key,\n",
    "            min_genes_per_gp=min_genes_per_gp,\n",
    "            min_source_genes_per_gp=min_source_genes_per_gp,\n",
    "            min_target_genes_per_gp=min_target_genes_per_gp,\n",
    "            max_genes_per_gp=None,\n",
    "            max_source_genes_per_gp=None,\n",
    "            max_target_genes_per_gp=None)\n",
    "        \n",
    "    # Summarize gene programs\n",
    "    print(f\"Number of gene programs with probed genes: {len(adata.uns['autotalker_gp_names'])}.\")\n",
    "    print(f\"Example gene programs: {random.sample(list(adata.uns['autotalker_gp_names']), 5)}.\")\n",
    "    print(f\"Number of gene program target genes: {adata.varm['autotalker_gp_targets'].sum()}.\")\n",
    "    print(f\"Number of gene program source genes: {adata.varm['autotalker_gp_sources'].sum()}.\")\n",
    "\n",
    "    # Loop `n_iters` times through combination of hyperparams \n",
    "    iters = range(n_iters)\n",
    "    hyperparams, hyperparam_values = zip(*hyperparam_option_dict.items())\n",
    "    for hyperparam_comb in itertools.product(*hyperparam_values, iters):\n",
    "        hyperparam_dict = {}\n",
    "        for hyperparam, hyperparam_value in zip(hyperparams, hyperparam_comb):\n",
    "            hyperparam_dict[hyperparam] = hyperparam_value\n",
    "        \n",
    "        experiment = mlflow.set_experiment(experiment_name)\n",
    "            \n",
    "        # Log dataset params\n",
    "        mlflow.log_param(\"dataset\", dataset)\n",
    "        mlflow.log_param(\"n_nodes\", n_nodes)\n",
    "        mlflow.log_param(\"n_genes\", n_genes)\n",
    "    \n",
    "        # Log gp mask params\n",
    "        mlflow.log_param(\"gp_mask\", gp_mask)\n",
    "        mlflow.log_param(\"nichenet_keep_target_ratio\", nichenet_keep_target_ratio)\n",
    "        mlflow.log_param(\"omnipath_min_curation_effort\", omnipath_min_curation_effort)\n",
    "        mlflow.log_param(\"gp_filter_mode\", gp_filter_mode)\n",
    "        mlflow.log_param(\"combine_overlap_gps\", combine_overlap_gps)\n",
    "        mlflow.log_param(\"overlap_thresh_source_genes\", overlap_thresh_source_genes)\n",
    "        mlflow.log_param(\"overlap_thresh_target_genes\", overlap_thresh_target_genes)\n",
    "        mlflow.log_param(\"overlap_thresh_genes\", overlap_thresh_genes)\n",
    "        mlflow.log_param(\"min_genes_per_gp\", min_genes_per_gp)\n",
    "        mlflow.log_param(\"min_source_genes_per_gp\", min_source_genes_per_gp)\n",
    "        mlflow.log_param(\"min_target_genes_per_gp\", min_target_genes_per_gp) \n",
    "        \n",
    "        if save_figures:\n",
    "            # Get time for timestamping saved artifacts\n",
    "            now = datetime.now()\n",
    "            current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")\n",
    "\n",
    "            benchmark_fig_run_dir = f\"{figure_path}/{dataset}/benchmarking/{experiment_name}/runs/{current_timestamp}\"\n",
    "            os.makedirs(benchmark_fig_run_dir, exist_ok=True)\n",
    "            benchmark_model_run_dir = f\"{model_artifacts_path}/{dataset}/benchmarking/{experiment_name}/runs/{current_timestamp}\"\n",
    "            os.makedirs(benchmark_model_run_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy adata\n",
    "        adata_run = adata.copy()\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"--- SPATIAL CONNECTIVITY ---\")\n",
    "        # Compute spatial neighborhood\n",
    "        sq.gr.spatial_neighbors(adata_run,\n",
    "                                coord_type=\"generic\",\n",
    "                                spatial_key=spatial_key,\n",
    "                                radius=hyperparam_dict[\"radius\"])\n",
    "        # ax = sns.histplot(np.squeeze(np.asarray(adata_run.obsp['spatial_connectivities'].sum(axis=0))),\n",
    "        #                   discrete=True)\n",
    "        # ax.set_title(\"Node Counts Per Number of Neighbors\")\n",
    "        # ax.set_ylabel(\"Node Count\")\n",
    "        # ax.set_xlabel(\"Number of Neighbors\")\n",
    "        # fig = ax.figure\n",
    "        # fig.savefig(f\"{benchmark_fig_run_dir}/node_counts_per_n_neighs.png\",\n",
    "        #             bbox_inches=\"tight\")\n",
    "        # plt.close(fig)\n",
    "        avg_edges_per_node = round(adata_run.obsp['spatial_connectivities'].sum(axis=0).mean(), 2)\n",
    "        print(f\"Average number of edges per node: {avg_edges_per_node}.\")\n",
    "        n_edges = int(sp.triu(adata_run.obsp['spatial_connectivities'], k=1).sum())\n",
    "        print(f\"Number of total edges: {n_edges}.\")\n",
    "        mlflow.log_param(\"avg_n_neighbors\", avg_edges_per_node)\n",
    "        mlflow.log_param(\"n_edges\", n_edges)\n",
    "        avg_n_neighbors_rounded = int(round(avg_edges_per_node))\n",
    "\n",
    "        # Initialize model\n",
    "        print(\"\")\n",
    "        if hyperparam_dict[\"n_hidden_encoder_divisor\"] is None:\n",
    "            n_hidden_encoder = len(adata.uns[gp_names_key]) # gp mask size\n",
    "        else:\n",
    "            n_hidden_encoder = int(len(adata.var) / hyperparam_dict[\"n_hidden_encoder_divisor\"])\n",
    "        model = Autotalker(adata_run,\n",
    "                           counts_key=counts_key,\n",
    "                           adj_key=adj_key,\n",
    "                           gp_names_key=gp_names_key,\n",
    "                           active_gp_names_key=active_gp_names_key,\n",
    "                           gp_targets_mask_key=gp_targets_mask_key,\n",
    "                           gp_sources_mask_key=gp_sources_mask_key,\n",
    "                           latent_key=latent_key,\n",
    "                           gene_expr_recon_dist=hyperparam_dict[\"gene_expr_recon_dist\"],\n",
    "                           node_label_method=hyperparam_dict[\"node_label_method\"],\n",
    "                           active_gp_thresh_ratio=hyperparam_dict[\"active_gp_thresh_ratio\"],\n",
    "                           n_hidden_encoder=n_hidden_encoder,\n",
    "                           conv_layer_encoder=hyperparam_dict[\"conv_layer_encoder\"],\n",
    "                           encoder_n_attention_heads=hyperparam_dict[\"encoder_n_attention_heads\"])\n",
    "\n",
    "        # Train model\n",
    "        print(\"\")\n",
    "        model.train(n_epochs=hyperparam_dict[\"n_epochs\"],\n",
    "                    n_epochs_all_gps=hyperparam_dict[\"n_epochs_all_gps\"],\n",
    "                    lr=hyperparam_dict[\"lr\"],\n",
    "                    lambda_edge_recon=hyperparam_dict[\"lambda_edge_recon\"],\n",
    "                    lambda_gene_expr_recon=hyperparam_dict[\"lambda_gene_expr_recon\"],\n",
    "                    lambda_group_lasso=hyperparam_dict[\"lambda_group_lasso\"],\n",
    "                    edge_batch_size=hyperparam_dict[\"batch_size\"],\n",
    "                    node_batch_size=hyperparam_dict[\"batch_size\"],\n",
    "                    mlflow_experiment_id=experiment.experiment_id,\n",
    "                    verbose=True)\n",
    "        \n",
    "        if save_figures:\n",
    "            # Log visualizations\n",
    "            # Use autotalker latent space for UMAP generation\n",
    "            sc.pp.neighbors(model.adata, use_rep=latent_key)\n",
    "            sc.tl.umap(model.adata, min_dist=0.3)\n",
    "\n",
    "            # Create subplot of cell-type annotations in spatial and latent space\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(10, 29))\n",
    "            title = fig.suptitle(t=\"Cell-type Annotations in Spatial and Latent Space\",\n",
    "                                 x=0.85,\n",
    "                                 y=0.925,\n",
    "                                 fontsize=20)\n",
    "            sc.pl.spatial(adata=model.adata,\n",
    "                          color=[cell_type_key],\n",
    "                          spot_size=0.03,\n",
    "                          title=\"Spatial Space\",\n",
    "                          ax=axs[0],\n",
    "                          show=False)\n",
    "            sc.pl.umap(adata=model.adata,\n",
    "                       color=[cell_type_key],\n",
    "                       title=\"Latent Space\",\n",
    "                       ax=axs[1],\n",
    "                       show=False)\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "            lgd = fig.legend(handles, labels, bbox_to_anchor=(1.225, 0.625))\n",
    "            axs[0].get_legend().remove()\n",
    "            axs[1].get_legend().remove()\n",
    "            plt.subplots_adjust(wspace=0, hspace=0.1)\n",
    "            fig.savefig(f\"{benchmark_fig_run_dir}/cell_type_annotations_in_spatial_and_latent_space.png\",\n",
    "                        bbox_extra_artists=(lgd, title),\n",
    "                        bbox_inches=\"tight\")\n",
    "            plt.close(fig)\n",
    "\n",
    "            # Create subplot of latent Leiden cluster annotations in latent and spatial space\n",
    "            resolution = 0.3\n",
    "            model.compute_latent_graph_connectivities(adata=model.adata,\n",
    "                                                      n_neighbors=int(round(avg_edges_per_node)),\n",
    "                                                      mode=\"knn\",\n",
    "                                                      seed=random_seed)\n",
    "            sc.tl.leiden(adata=model.adata,\n",
    "                         resolution=resolution,\n",
    "                         random_state=random_seed,\n",
    "                         key_added=f\"leiden_latent_{str(resolution)}\",\n",
    "                         adjacency=model.adata.obsp[\"latent_connectivities\"])\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(10, 20))\n",
    "            title = fig.suptitle(t=\"Latent Leiden Cluster Annotations in Latent and Spatial Space\",\n",
    "                                 x=0.85,\n",
    "                                 y=0.925,\n",
    "                                 fontsize=20)\n",
    "            sc.pl.umap(adata=model.adata,\n",
    "                       color=[f\"leiden_latent_{str(resolution)}\"],\n",
    "                       title=f\"Latent Space\",\n",
    "                       ax=axs[0],\n",
    "                       show=False)\n",
    "            sc.pl.spatial(adata=model.adata,\n",
    "                          color=[f\"leiden_latent_{str(resolution)}\"],\n",
    "                          spot_size=0.03,\n",
    "                          title=f\"Spatial Space\",\n",
    "                          ax=axs[1],\n",
    "                          show=False)\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "            lgd = fig.legend(handles, labels, bbox_to_anchor=(1.025, 0.7))\n",
    "            axs[0].get_legend().remove()\n",
    "            axs[1].get_legend().remove()\n",
    "            plt.subplots_adjust(wspace=0, hspace=0.1)\n",
    "            fig.savefig(f\"{benchmark_fig_run_dir}/latent_leiden_cluster_annotations_in_latent_and_spatial_space.png\",\n",
    "                        bbox_extra_artists=(lgd, title),\n",
    "                        bbox_inches=\"tight\")\n",
    "            plt.close(fig)\n",
    "\n",
    "            mlflow.log_artifacts(benchmark_fig_run_dir,\n",
    "                                 current_timestamp)\n",
    "        \n",
    "        if save_model:            \n",
    "            model.save(dir_path=benchmark_model_run_dir,\n",
    "                       overwrite=True,\n",
    "                       save_adata=True,\n",
    "                       adata_file_name=f\"{dataset}.h5ad\")\n",
    "\n",
    "        mlflow.end_run()\n",
    "        print(\"--------------------\")\n",
    "        print(\"\")\n",
    "        print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089dc00-0251-4131-861c-308489b66790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hyperparam_benchmarking_metrics(fig_title,\n",
    "                                         df,\n",
    "                                         y_col_name,\n",
    "                                         sort_col=\"val_mse_score\",\n",
    "                                         plot_ratio_active_gps=False,\n",
    "                                         save_fig=False,\n",
    "                                         file_name=\"benchmarking_metrics.png\"):\n",
    "    # Compute evaluation metric ranks for sorting\n",
    "    val_mse_score_ranks = (df.groupby([y_col_name])\n",
    "                           [\"val_mse_score\"].mean().rank(ascending=True)\n",
    "                           .rename(\"val_mse_score_rank\"))\n",
    "    val_auroc_score_ranks = (df.groupby([y_col_name])\n",
    "                                [\"val_auroc_score\"].mean().rank(ascending=False)\n",
    "                                .rename(\"val_auroc_score_rank\"))\n",
    "    df = df.merge(val_mse_score_ranks, on=[y_col_name])\n",
    "    df = df.merge(val_auroc_score_ranks, on=[y_col_name])\n",
    "\n",
    "    if sort_col == \"val_mse_score\":\n",
    "        df.sort_values(by=[\"val_mse_score_rank\", y_col_name],\n",
    "                       inplace=True,\n",
    "                       ascending=False)\n",
    "    elif sort_col == \"val_auroc_score\":\n",
    "        df.sort_values(by=[\"val_auroc_score_rank\", y_col_name],\n",
    "                       inplace=True,\n",
    "                       ascending=False)\n",
    "    elif sort_col == \"total_score\":\n",
    "        df[\"val_total_score_rank\"] = (df[\"val_mse_score_rank\"] + \n",
    "                                      df[\"val_auroc_score_rank\"]).rank(ascending=True)\n",
    "        df.sort_values(by=[\"val_total_score_rank\", y_col_name],\n",
    "                       inplace=True,\n",
    "                       ascending=False)\n",
    "    \n",
    "    if plot_ratio_active_gps:\n",
    "        fig, axes = plt.subplots(3, 1, sharey=True, figsize=(10, 20))\n",
    "        sns.boxplot(data=df, ax=axes[2], x=\"ratio_active_gps\", y=y_col_name)\n",
    "        axes[2].set_title(\"Ratio of Active Gene Programs\")\n",
    "    else:\n",
    "        fig, axes = plt.subplots(2, 1, sharey=True, figsize=(10, 15))\n",
    "    fig.suptitle(fig_title, fontsize=15)\n",
    "    sns.boxplot(data=df, ax=axes[0], x=\"val_auroc_score\", y=y_col_name)\n",
    "    axes[0].set_title(\"Edge Reconstruction Area Under ROC Curve\")\n",
    "    sns.boxplot(data=df, ax=axes[1], x=\"val_mse_score\", y=y_col_name)\n",
    "    axes[1].set_title(\"Gene Expression Reconstruction Mean Squared Error\")\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1,\n",
    "                        right=0.9,\n",
    "                        top=0.94,\n",
    "                        wspace=0.175,\n",
    "                        hspace=0.175)\n",
    "    if save_fig:\n",
    "        # Get time for timestamping saved artefacts\n",
    "        now = datetime.now()\n",
    "        current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")\n",
    "        benchmark_fig_run_dir = f\"{figure_path}/{dataset}/benchmarking/{experiment_name}/results/{current_timestamp}\"\n",
    "        os.makedirs(benchmark_fig_run_dir, exist_ok=True)\n",
    "        plt.savefig(f\"{benchmark_fig_run_dir}/{file_name}\",\n",
    "                    bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7332dc1-413d-4e64-9161-38115e91c450",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter Benchmarking Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864a28bf-fb6f-4442-a45c-0704350dd11a",
   "metadata": {},
   "source": [
    "### 2.1. Benchmark Loss Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3532074-40e0-4d92-a4f0-3fa32f25db52",
   "metadata": {},
   "source": [
    "- Different combinations of the edge reconstruction loss and gene expression reconstruction loss weighting hyperparameters are tested.\n",
    "- Average number of neighbors is varied. The radius is set in order to get an average number of neighbors of ```2```, ```4```, ```8```, ```16``` and ```32``` with 2 iterations respectively, resulting in a total of 10 runs per loss weight combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f8b40b-6435-421c-88fc-0d265f3ad3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"benchmark_loss_weights\"\n",
    "\n",
    "# Set hyperparameters that are not varied as part of the experiment\n",
    "hyperparam_option_dict = {}\n",
    "hyperparam_option_dict[\"node_label_method\"] = [\"one-hop-attention\"]\n",
    "hyperparam_option_dict[\"gene_expr_recon_dist\"] = [\"nb\"]\n",
    "hyperparam_option_dict[\"conv_layer_encoder\"] = [\"gcnconv\"]\n",
    "hyperparam_option_dict[\"encoder_n_attention_heads\"] = [0]\n",
    "hyperparam_option_dict[\"n_hidden_encoder_divisor\"] = [None]\n",
    "hyperparam_option_dict[\"active_gp_thresh_ratio\"] = [0.]\n",
    "hyperparam_option_dict[\"lambda_group_lasso\"] = [0]\n",
    "\n",
    "hyperparam_option_dict[\"n_epochs\"] = [20]\n",
    "hyperparam_option_dict[\"n_epochs_all_gps\"] = [10]\n",
    "hyperparam_option_dict[\"lr\"] = [0.001]\n",
    "hyperparam_option_dict[\"batch_size\"] = [64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa55161-9831-4c17-9731-cc897a551e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_option_dict[\"radius\"] = [0.03094, 0.03875, 0.05102, 0.07200, 0.10241]\n",
    "hyperparam_option_dict[\"lambda_edge_recon\"] = [0, 0.1, 0.2, 0.33, 0.5, 1.]\n",
    "hyperparam_option_dict[\"lambda_gene_expr_recon\"] = [1.]\n",
    "\n",
    "model = run_hyperparam_benchmarking(dataset=dataset,\n",
    "                                    hyperparam_option_dict=hyperparam_option_dict,\n",
    "                                    n_iters=2,\n",
    "                                    experiment_name=experiment_name,\n",
    "                                    gp_mask=\"combined_priors\",\n",
    "                                    save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2424a1b6-e24f-4c2c-b8cb-3282181bc9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_option_dict[\"radius\"] = [0.10241] # [0.03094, 0.03875, 0.05102, 0.07200, 0.10241]\n",
    "hyperparam_option_dict[\"lambda_edge_recon\"] = [1.]\n",
    "hyperparam_option_dict[\"lambda_gene_expr_recon\"] = [0, 0.1, 0.2, 0.33, 0.5]\n",
    "\n",
    "model = run_hyperparam_benchmarking(dataset=dataset,\n",
    "                                    hyperparam_option_dict=hyperparam_option_dict,\n",
    "                                    n_iters=2,\n",
    "                                    experiment_name=experiment_name,\n",
    "                                    gp_mask=\"combined_priors\",\n",
    "                                    save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e46e48-3231-447d-a7f6-eb480a0c5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(experiment_names=[experiment_name],\n",
    "                          output_format=\"list\")\n",
    "\n",
    "data = []\n",
    "for run in runs:\n",
    "    data.append({**run.data.metrics, **run.data.params})\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "def get_loss_weights(row):  \n",
    "    return f\"lambda_edge_recon_{row['lambda_edge_recon_']}_+_lambda_gene_expr_recon_{row['lambda_gene_expr_recon_']}\"\n",
    "df[\"loss_weights\"] = df.apply(lambda row: get_loss_weights(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d640db5a-7962-41d7-a64b-dc01e5b80602",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_metrics(fig_title=\"Loss Weights Benchmarking Evaluation Metrics\",\n",
    "                  df=df,\n",
    "                  y_col_name=\"loss_weights\",\n",
    "                  plot_ratio_active_gps=False,\n",
    "                  file_name=\"loss_weights_benchmarking_eval_metrics.png\",\n",
    "                  save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2812dbb-761b-4083-87aa-4e3cd9b9ff4a",
   "metadata": {},
   "source": [
    "### 2.2. Benchmark Node Label Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad5223e-37f1-4a64-a017-bdec0703f835",
   "metadata": {},
   "source": [
    "- Different node label methods are tested.\n",
    "- Average number of neighbors is varied. The radius is set in order to get an average number of neighbors of ```2```, ```4```, ```8```, ```16``` and ```32``` with 2 iterations respectively, resulting in a total of 10 runs per node label method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a0c0c7-fdaa-4bf9-b81c-e3d2f8ee3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"benchmark_node_label_method\"\n",
    "\n",
    "# Set hyperparameters that are not varied as part of the experiment\n",
    "hyperparam_option_dict = {}\n",
    "hyperparam_option_dict[\"lambda_edge_recon\"] = [1.]\n",
    "hyperparam_option_dict[\"lambda_gene_expr_recon\"] = [0.33]\n",
    "hyperparam_option_dict[\"gene_expr_recon_dist\"] = [\"nb\"]\n",
    "hyperparam_option_dict[\"conv_layer_encoder\"] = [\"gcnconv\"]\n",
    "hyperparam_option_dict[\"encoder_n_attention_heads\"] = [0]\n",
    "hyperparam_option_dict[\"n_hidden_encoder_divisor\"] = [None]\n",
    "hyperparam_option_dict[\"active_gp_thresh_ratio\"] = [0.]\n",
    "hyperparam_option_dict[\"lambda_group_lasso\"] = [0]\n",
    "\n",
    "hyperparam_option_dict[\"n_epochs\"] = [20]\n",
    "hyperparam_option_dict[\"n_epochs_all_gps\"] = [10]\n",
    "hyperparam_option_dict[\"lr\"] = [0.001]\n",
    "hyperparam_option_dict[\"batch_size\"] = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d37eba-2f74-43c3-b6ff-862c3d0d074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_option_dict[\"radius\"] = [0.03094, 0.03875, 0.05102, 0.07200, 0.10241]\n",
    "hyperparam_option_dict[\"node_label_method\"] = [\"one-hop-attention\", \"one-hop-norm\", \"one-hop-sum\"]\n",
    "\n",
    "model = run_hyperparam_benchmarking(dataset=dataset,\n",
    "                                    hyperparam_option_dict=hyperparam_option_dict,\n",
    "                                    n_iters=2,\n",
    "                                    experiment_name=experiment_name,\n",
    "                                    gp_mask=\"combined_priors\",\n",
    "                                    save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf57b328-1373-42d0-897f-3a79b2bddb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(experiment_names=[experiment_name],\n",
    "                          output_format=\"list\")\n",
    "\n",
    "data = []\n",
    "for run in runs:\n",
    "    data.append({**run.data.metrics, **run.data.params})\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c093b-4326-4424-bb37-5df881dc3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_metrics(fig_title=\"Node Label Method Benchmarking Evaluation Metrics\",\n",
    "                  df=df,\n",
    "                  y_col_name=\"node_label_method_\",\n",
    "                  plot_ratio_active_gps=False,\n",
    "                  file_name=\"node_label_method_benchmarking_eval_metrics.png\",\n",
    "                  save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044a2e48-32d0-4d6d-b112-69be3a613dd0",
   "metadata": {},
   "source": [
    "### 2.3. Benchmark Gene Expression Reconstruction Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffa56f0-a86f-495f-ab33-18c75800566c",
   "metadata": {},
   "source": [
    "- Different gene expression reconstruction distributions are tested.\n",
    "- Average number of neighbors is varied. The radius is set in order to get an average number of neighbors of ```2```, ```4```, ```8```, ```16``` and ```32``` with 2 iterations respectively, resulting in a total of 10 runs per gene expression reconstruction distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70271076-445b-4c64-9a42-d2ad46e6b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"benchmark_gene_expr_recon_dist\"\n",
    "\n",
    "# Set hyperparameters that are not varied as part of the experiment\n",
    "hyperparam_option_dict = {}\n",
    "hyperparam_option_dict[\"lambda_edge_recon\"] = [1.]\n",
    "hyperparam_option_dict[\"lambda_gene_expr_recon\"] = [0.33]\n",
    "hyperparam_option_dict[\"node_label_method\"] = [\"one-hop-attention\"]\n",
    "hyperparam_option_dict[\"conv_layer_encoder\"] = [\"gcnconv\"]\n",
    "hyperparam_option_dict[\"encoder_n_attention_heads\"] = [0]\n",
    "hyperparam_option_dict[\"n_hidden_encoder_divisor\"] = [None]\n",
    "hyperparam_option_dict[\"active_gp_thresh_ratio\"] = [0.]\n",
    "hyperparam_option_dict[\"lambda_group_lasso\"] = [0]\n",
    "\n",
    "hyperparam_option_dict[\"n_epochs\"] = [20]\n",
    "hyperparam_option_dict[\"n_epochs_all_gps\"] = [10]\n",
    "hyperparam_option_dict[\"lr\"] = [0.001]\n",
    "hyperparam_option_dict[\"batch_size\"] = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8d585-5f37-45df-8fd9-62cc2f39ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_option_dict[\"radius\"] = [0.03094, 0.03875, 0.05102, 0.07200, 0.10241]\n",
    "hyperparam_option_dict[\"gene_expr_recon_dist\"] = [\"nb\", \"zinb\"]\n",
    "\n",
    "model = run_hyperparam_benchmarking(dataset=dataset,\n",
    "                                    hyperparam_option_dict=hyperparam_option_dict,\n",
    "                                    n_iters=2,\n",
    "                                    experiment_name=experiment_name,\n",
    "                                    gp_mask=\"combined_priors\",\n",
    "                                    save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe32af-89b6-4f7b-b21e-e9a537240830",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(experiment_names=[experiment_name],\n",
    "                          output_format=\"list\")\n",
    "\n",
    "data = []\n",
    "for run in runs:\n",
    "    data.append({**run.data.metrics, **run.data.params})\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2bf032-3cca-42dd-ab4a-6df264467b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_metrics(fig_title=\"Gene Expression Reconstruction Distribution Benchmarking Evaluation Metrics\",\n",
    "                  df=df,\n",
    "                  y_col_name=\"gene_expr_recon_dist_\",\n",
    "                  plot_ratio_active_gps=False,\n",
    "                  file_name=\"gene_expr_recon_dist_benchmarking_eval_metrics.png\",\n",
    "                  save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46fd7da-d441-4930-993c-d2097143f000",
   "metadata": {},
   "source": [
    "### 2.4. Benchmark Encoder Layer Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b689e-68f9-4e6c-9b3c-427985059331",
   "metadata": {},
   "source": [
    "- Different encoder layer architectures are tested.\n",
    "- Average number of neighbors is varied. The radius is set in order to get an average number of neighbors of ```2```, ```4```, ```8```, ```16``` and ```32``` with 2 iterations respectively, resulting in a total of 10 runs per encoder layer architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad3c72-96b2-4af2-b424-13d83095734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"benchmark_encoder_layer_arch\"\n",
    "\n",
    "# Set hyperparameters that are not varied as part of the experiment\n",
    "hyperparam_option_dict = {}\n",
    "hyperparam_option_dict[\"lambda_edge_recon\"] = [1.]\n",
    "hyperparam_option_dict[\"lambda_gene_expr_recon\"] = [0.2]\n",
    "hyperparam_option_dict[\"node_label_method\"] = [\"one-hop-attention\"]\n",
    "hyperparam_option_dict[\"gene_expr_recon_dist\"] = [\"nb\"]\n",
    "hyperparam_option_dict[\"n_hidden_encoder_divisor\"] = [None]\n",
    "hyperparam_option_dict[\"active_gp_thresh_ratio\"] = [0.]\n",
    "hyperparam_option_dict[\"lambda_group_lasso\"] = [0]\n",
    "\n",
    "hyperparam_option_dict[\"n_epochs\"] = [20]\n",
    "hyperparam_option_dict[\"n_epochs_all_gps\"] = [10]\n",
    "hyperparam_option_dict[\"lr\"] = [0.001]\n",
    "hyperparam_option_dict[\"batch_size\"] = [64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf17045e-048e-46f3-a545-4178b1a85f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_option_dict[\"radius\"] = [0.03094, 0.03875, 0.05102, 0.07200, 0.10241]\n",
    "hyperparam_option_dict[\"conv_layer_encoder\"] = [\"gcnconv\"]\n",
    "hyperparam_option_dict[\"encoder_n_attention_heads\"] = [0]\n",
    "\n",
    "model = run_hyperparam_benchmarking(dataset=dataset,\n",
    "                                    hyperparam_option_dict=hyperparam_option_dict,\n",
    "                                    n_iters=2,\n",
    "                                    experiment_name=experiment_name,\n",
    "                                    gp_mask=\"combined_priors\",\n",
    "                                    save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d439b-4eca-48b3-9dbf-0bf7cb857e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_option_dict[\"radius\"] = [0.03094, 0.03875, 0.05102, 0.07200, 0.10241]\n",
    "hyperparam_option_dict[\"conv_layer_encoder\"] = [\"gatv2conv\"]\n",
    "hyperparam_option_dict[\"encoder_n_attention_heads\"] = [1, 2, 4, 8]\n",
    "\n",
    "model = run_hyperparam_benchmarking(dataset=dataset,\n",
    "                                    hyperparam_option_dict=hyperparam_option_dict,\n",
    "                                    n_iters=2,\n",
    "                                    experiment_name=experiment_name,\n",
    "                                    gp_mask=\"combined_priors\",\n",
    "                                    save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85c31ff-8b68-4747-bfbc-15732ba96520",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(experiment_names=[experiment_name],\n",
    "                          output_format=\"list\")\n",
    "\n",
    "data = []\n",
    "for run in runs:\n",
    "    data.append({**run.data.metrics, **run.data.params})\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "def get_encoder_layer_arch(row):  \n",
    "    return f\"conv_layer_encoder_{row['conv_layer_encoder_']}_+_encoder_n_attention_heads_{row['encoder_n_attention_heads_']}\"\n",
    "df[\"encoder_layer_arch\"] = df.apply(lambda row: get_encoder_layer_arch(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca492888-8665-4ba9-ad63-9984a8584f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hyperparam_benchmarking_metrics(fig_title=\"Encoder Layer Architecture Benchmarking Evaluation Metrics\",\n",
    "                                     df=df,\n",
    "                                     y_col_name=\"encoder_layer_arch\",\n",
    "                                     plot_ratio_active_gps=False,\n",
    "                                     file_name=\"encoder_layer_arch_benchmarking_eval_metrics.png\",\n",
    "                                     save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c6803-be46-4c5f-b929-897cd0a74d04",
   "metadata": {},
   "source": [
    "### 2.5. Benchmark Encoder Hidden Layer Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08602dba-c435-4ba5-aefd-c04f4af92cdd",
   "metadata": {},
   "source": [
    "- Different sizes of the encoder hidden layer are tested.\n",
    "- Average number of neighbors is varied. The radius is set in order to get an average number of neighbors of ```2```, ```4```, ```8```, ```16``` and ```32``` with 2 iterations respectively, resulting in a total of 10 runs per encoder hidden layer size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c93e2-b701-4d66-9f27-a8d97ff4633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"benchmark_encoder_n_hidden\"\n",
    "\n",
    "# Set hyperparameters that are not varied as part of the experiment\n",
    "hyperparam_option_dict = {}\n",
    "hyperparam_option_dict[\"lambda_edge_recon\"] = [1.]\n",
    "hyperparam_option_dict[\"lambda_gene_expr_recon\"] = [0.33]\n",
    "hyperparam_option_dict[\"node_label_method\"] = [\"one-hop-attention\"]\n",
    "hyperparam_option_dict[\"gene_expr_recon_dist\"] = [\"nb\", \"zinb\"]\n",
    "hyperparam_option_dict[\"conv_layer_encoder\"] = [\"gcnconv\"]\n",
    "hyperparam_option_dict[\"encoder_n_attention_heads\"] = [0]\n",
    "hyperparam_option_dict[\"active_gp_thresh_ratio\"] = [0.]\n",
    "hyperparam_option_dict[\"lambda_group_lasso\"] = [0]\n",
    "\n",
    "hyperparam_option_dict[\"n_epochs\"] = [20]\n",
    "hyperparam_option_dict[\"n_epochs_all_gps\"] = [10]\n",
    "hyperparam_option_dict[\"lr\"] = [0.001]\n",
    "hyperparam_option_dict[\"batch_size\"] = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3138e-7a0c-410d-9407-22b5825cd8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_option_dict[\"radius\"] = [0.03094, 0.03875, 0.05102, 0.07200, 0.10241]\n",
    "hyperparam_option_dict[\"n_hidden_encoder_divisor\"] = [None, 0.5, 1., 2.]\n",
    "\n",
    "model = run_hyperparam_benchmarking(dataset=dataset,\n",
    "                                    hyperparam_option_dict=hyperparam_option_dict,\n",
    "                                    n_iters=2,\n",
    "                                    experiment_name=experiment_name,\n",
    "                                    gp_mask=\"combined_priors\",\n",
    "                                    save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd8899-fc3b-42b7-87dc-8866827f9008",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(experiment_names=[experiment_name],\n",
    "                          output_format=\"list\")\n",
    "\n",
    "data = []\n",
    "for run in runs:\n",
    "    data.append({**run.data.metrics, **run.data.params})\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d85b6-2a78-4a15-bdb2-bb124d9627ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_metrics(fig_title=\"Encoder Hidden Layer Size Benchmarking Evaluation Metrics\",\n",
    "                  df=df,\n",
    "                  y_col_name=\"encoder_n_hidden_\",\n",
    "                  plot_ratio_active_gps=False,\n",
    "                  file_name=\"encoder_n_hidden_benchmarking_eval_metrics.png\",\n",
    "                  save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23fc911-a226-4766-805a-f769d6adbc8d",
   "metadata": {},
   "source": [
    "### 2.6. Benchmark Active Gene Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ed3be-bc7a-4631-98e3-d34530c0cd0e",
   "metadata": {},
   "source": [
    "- Different combinations of the active gene program threshold ratio and the group lasso regularization weighting hyperparameter are tested. Both these hyperparameters contribute to a reduction of active gene programs.\n",
    "- Average number of neighbors is varied. The radius is set in order to get an average number of neighbors of ```2```, ```4```, ```8```, ```16``` and ```32``` with 2 iterations respectively, resulting in a total of 10 runs per active gp hyperparameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87d1e38-f428-4ae6-9062-d900d5494f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"benchmark_active_gps\"\n",
    "\n",
    "# Set hyperparameters that are not varied as part of the experiment\n",
    "hyperparam_option_dict = {}\n",
    "hyperparam_option_dict[\"lambda_edge_recon\"] = [1.]\n",
    "hyperparam_option_dict[\"lambda_gene_expr_recon\"] = [0.33]\n",
    "hyperparam_option_dict[\"node_label_method\"] = [\"one-hop-attention\"]\n",
    "hyperparam_option_dict[\"gene_expr_recon_dist\"] = [\"nb\", \"zinb\"]\n",
    "hyperparam_option_dict[\"conv_layer_encoder\"] = [\"gcnconv\"]\n",
    "hyperparam_option_dict[\"encoder_n_attention_heads\"] = [0]\n",
    "hyperparam_option_dict[\"n_hidden_encoder_divisor\"] = [None]\n",
    "\n",
    "hyperparam_option_dict[\"n_epochs\"] = [20]\n",
    "hyperparam_option_dict[\"n_epochs_all_gps\"] = [10]\n",
    "hyperparam_option_dict[\"lr\"] = [0.001]\n",
    "hyperparam_option_dict[\"batch_size\"] = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cecf9c-b7d7-4390-a21c-a6cd47d6b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_option_dict[\"radius\"] = [0.03094, 0.03875, 0.05102, 0.07200, 0.10241]\n",
    "hyperparam_option_dict[\"active_gp_thresh_ratio\"] = [0., 0.01, 0.03, 0.1, 0.3]\n",
    "hyperparam_option_dict[\"lambda_group_lasso\"] = [0, 0.01, 0.03, 0.1, 0.3]\n",
    "\n",
    "model = run_hyperparam_benchmarking(dataset=dataset,\n",
    "                                    hyperparam_option_dict=hyperparam_option_dict,\n",
    "                                    n_iters=2,\n",
    "                                    experiment_name=experiment_name,\n",
    "                                    gp_mask=\"combined_priors\",\n",
    "                                    save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a353f4-36f6-45d4-871e-a79529ff8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(experiment_names=[experiment_name],\n",
    "                          output_format=\"list\")\n",
    "\n",
    "data = []\n",
    "for run in runs:\n",
    "    data.append({**run.data.metrics, **run.data.params})\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Get active gene program ratio\n",
    "def get_ratio_active_gps(row):\n",
    "    return row[\"n_active_gps\"] / (int(row[\"n_nonaddon_gps_\"]) + int(row[\"n_addon_gps_\"]))\n",
    "df[\"ratio_active_gps\"] = df.apply(lambda row: get_ratio_active_gps(row), axis=1)\n",
    "\n",
    "# Get combination of active gene program threshold and lambda group lasso\n",
    "def get_active_gp_thresh_lambda_group_lasso(row):\n",
    "    return f\"active_gp_thresh_{row['active_gp_thresh_ratio_']}_+_lambda_group_lasso_{row['lambda_group_lasso_']}\"\n",
    "df[\"active_gp_thresh_lambda_group_lasso\"] = df.apply(lambda row: get_active_gp_thresh_lambda_group_lasso(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa715ba-3bb0-4821-9b08-c41594145071",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_metrics(fig_title=\"Active GP Benchmarking Evaluation Metrics\",\n",
    "                  df=df,\n",
    "                  y_col_name=\"active_gp_thresh_lambda_group_lasso\",\n",
    "                  plot_ratio_active_gps=True,\n",
    "                  file_name=\"active_gp_benchmarking_eval_metrics.png\",\n",
    "                  save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c93e1-47e9-4a5b-883d-7712693d39df",
   "metadata": {},
   "source": [
    "## 3. Method Benchmarking Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e90e7c8-12c1-476d-969e-3831d4e0fbef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
